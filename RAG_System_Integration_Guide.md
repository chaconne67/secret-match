# ğŸ§  [ê¸°ìˆ  ë¬¸ì„œ] ì´ˆê²½ëŸ‰ RAG ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ê³„ë„ ë° ì„¤ì¹˜ ê°€ì´ë“œ

> **"5ë¶„ ë§Œì— ë‹¹ì‹ ì˜ AIì— 'ì¥ê¸° ê¸°ì–µ'ì„ ì‹¬ìœ¼ì„¸ìš”."**
> SQLiteì™€ OpenAI ì„ë² ë”©ì„ í™œìš©í•œ **Serverlessê¸‰ ì´ˆê²½ëŸ‰ RAG(Retrieval-Augmented Generation)** ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë³µì¡í•œ Vector DB ì„¤ì¹˜ ì—†ì´ ë¡œì»¬ íŒŒì¼ í•˜ë‚˜ë¡œ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.

---

## 1. System Architecture (ì„¤ê³„ë„)

```mermaid
graph TD
    User[ì‚¬ìš©ì/AI ì—ì´ì „íŠ¸] -->|1. ì§ˆë¬¸ (Query)| API[Flask API Server]
    API -->|2. ì„ë² ë”© ë³€í™˜| OpenAI[OpenAI Embedding API]
    API -->|3. ë²¡í„° ê²€ìƒ‰ (Cosine Sim)| DB[(SQLite Database)]
    DB -->|4. ìœ ì‚¬ ëŒ€í™” ë°˜í™˜| API
    API -->|5. ê¸°ì–µ ì£¼ì… (Context)| LLM[LLM (GPT/Claude)]
    LLM -->|6. ë‹µë³€ ìƒì„±| User
```

### ğŸ’ í•µì‹¬ íŠ¹ì§•
*   **Zero Infrastructure**: ë³„ë„ì˜ Vector DB(Pinecone, Milvus ë“±) ì„¤ì¹˜ ë¶ˆí•„ìš”. `memory.db` íŒŒì¼ í•˜ë‚˜ë¡œ ë.
*   **Hybrid Storage**: ëŒ€í™” ë‚´ìš©(Text)ê³¼ ì„ë² ë”© ë²¡í„°(JSON)ë¥¼ í•˜ë‚˜ì˜ SQLite í…Œì´ë¸”ì— ì €ì¥.
*   **Cost Effective**: ê²€ìƒ‰ ë¹„ìš© $0 (ë¡œì»¬ ì—°ì‚°). ì„ë² ë”© ìƒì„± ë¹„ìš©ë§Œ ë°œìƒ ($0.02/1M tokens).
*   **Standard API**: REST API ì œê³µìœ¼ë¡œ ì–´ë–¤ ì–¸ì–´/í”„ë ˆì„ì›Œí¬ì™€ë„ ì—°ë™ ê°€ëŠ¥.

---

## 2. Quick Start (ì„¤ì¹˜ ê°€ì´ë“œ)

### ì „ì œ ì¡°ê±´
*   Python 3.9 ì´ìƒ
*   OpenAI API Key

### ğŸš€ 3ë‹¨ê³„ ì„¤ì¹˜ë²•

**Step 1: í”„ë¡œì íŠ¸ í´ë¡  ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜**
```bash
# í”„ë¡œì íŠ¸ í´ë” ìƒì„±
mkdir my-rag-memory
cd my-rag-memory

# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai flask flask-cors python-dotenv numpy scikit-learn
```

**Step 2: í™˜ê²½ ì„¤ì •**
`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
```env
OPENAI_API_KEY=sk-your-api-key-here
DB_PATH=data/memory.db
```

**Step 3: DB ì´ˆê¸°í™” ë° ì„œë²„ ì‹¤í–‰**
(ì•„ë˜ ì½”ë“œë¥¼ `server.py`ë¡œ ì €ì¥ í›„ ì‹¤í–‰)

```python
# server.py (ê°„ì†Œí™”ëœ ë²„ì „)
from flask import Flask, request, jsonify
import sqlite3, json, os, numpy as np
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity
from dotenv import load_dotenv

load_dotenv()
app = Flask(__name__)
client = OpenAI()
DB_PATH = os.getenv('DB_PATH', 'memory.db')

# DB ì´ˆê¸°í™”
def init_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute('''CREATE TABLE IF NOT EXISTS memories 
                    (id INTEGER PRIMARY KEY, content TEXT, embedding TEXT)''')
    conn.close()

init_db()

# ì„ë² ë”© ìƒì„±
def get_embedding(text):
    return client.embeddings.create(input=text, model="text-embedding-3-small").data[0].embedding

@app.route('/add', methods=['POST'])
def add_memory():
    data = request.json
    emb = json.dumps(get_embedding(data['content']))
    conn = sqlite3.connect(DB_PATH)
    conn.execute("INSERT INTO memories (content, embedding) VALUES (?, ?)", (data['content'], emb))
    conn.commit()
    conn.close()
    return jsonify({"status": "saved"})

@app.route('/search', methods=['POST'])
def search_memory():
    query = request.json['query']
    query_vec = get_embedding(query)
    
    conn = sqlite3.connect(DB_PATH)
    rows = conn.execute("SELECT content, embedding FROM memories").fetchall()
    conn.close()
    
    results = []
    for content, emb_json in rows:
        score = cosine_similarity([query_vec], [json.loads(emb_json)])[0][0]
        results.append({"content": content, "score": float(score)})
    
    # Top 5 ë°˜í™˜
    return jsonify(sorted(results, key=lambda x: x['score'], reverse=True)[:5])

if __name__ == '__main__':
    app.run(port=5000)
```

```bash
python server.py
```
ğŸ‘‰ ì´ì œ `http://localhost:5000`ì—ì„œ ê¸°ì–µ ì‹œìŠ¤í…œì´ ë™ì‘í•©ë‹ˆë‹¤!

---

## 3. API Reference (ì‚¬ìš©ë²•)

### ğŸ“¥ ê¸°ì–µ ì €ì¥ (Add Memory)
ëŒ€í™” ë¡œê·¸ë‚˜ ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

**Request:** `POST /add`
```json
{
  "content": "Secret Match í”„ë¡œì íŠ¸ì˜ íƒ€ê²Ÿì€ 25-39ì„¸ í˜„ì‹¤ì  ë‚­ë§Œì£¼ì˜ìì…ë‹ˆë‹¤."
}
```

### ğŸ” ê¸°ì–µ ê²€ìƒ‰ (Search Memory)
ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê³¼ê±° ê¸°ì–µì„ ì°¾ìŠµë‹ˆë‹¤.

**Request:** `POST /search`
```json
{
  "query": "Secret Match íƒ€ê²Ÿì´ ëˆ„êµ¬ì•¼?"
}
```

**Response:**
```json
[
  {
    "content": "Secret Match í”„ë¡œì íŠ¸ì˜ íƒ€ê²Ÿì€ 25-39ì„¸ í˜„ì‹¤ì  ë‚­ë§Œì£¼ì˜ìì…ë‹ˆë‹¤.",
    "score": 0.892
  }
]
```

---

## 4. í™œìš© ì‹œë‚˜ë¦¬ì˜¤ (Integration Patterns)

### ğŸ¤– AI ì±—ë´‡ì— ì ìš©í•˜ê¸°
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ë¨¼ì € ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.

```python
# 1. ì‚¬ìš©ì ì§ˆë¬¸
user_query = "ìš°ë¦¬ íƒ€ê²Ÿì´ ëˆ„êµ¬ì˜€ì§€?"

# 2. ê¸°ì–µ ê²€ìƒ‰ (RAG)
memories = requests.post("http://localhost:5000/search", json={"query": user_query}).json()
context = "\n".join([m['content'] for m in memories])

# 3. LLM í”„ë¡¬í”„íŠ¸ ì£¼ì…
prompt = f"""
ì°¸ê³  ì •ë³´(Memory):
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {user_query}
ë‹µë³€:
"""

# 4. LLM í˜¸ì¶œ
response = openai.ChatCompletion.create(model="gpt-4", messages=[{"role": "user", "content": prompt}])
```

---

## 5. í™•ì¥ì„± (Scalability)

*   **ë°ì´í„°ê°€ ë§ì•„ì§€ë©´?**: SQLiteëŠ” ìˆ˜ì‹­ë§Œ ê±´ê¹Œì§€ ë¬¸ì œì—†ìŠµë‹ˆë‹¤. ë°±ë§Œ ê±´ ì´ìƒì´ë©´ `pgvector`(PostgreSQL)ë‚˜ `Qdrant`ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ì„¸ìš”.
*   **ë³´ì•ˆ**: ì´ ì‹œìŠ¤í…œì€ ë¡œì»¬ì—ì„œ ì‘ë™í•˜ë¯€ë¡œ ë°ì´í„°ê°€ ì™¸ë¶€ë¡œ ìœ ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (OpenAI APIë¡œ ì „ì†¡ë˜ëŠ” í…ìŠ¤íŠ¸ ì œì™¸)

---
*Created: 2026-02-05*
*Author: Judy (AIìë§Œì¶” Team)*


---
[ğŸ  ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°](README.md)